# ğŸ“š Motia Smart PDF Assistant (Advanced RAG)

A full-stack AI application that allows users to upload PDF documents and chat with them in real-time. 

This project demonstrates the power of **Motia's Polyglot Architecture**, seamlessly blending **TypeScript** (for API/Frontend) and **Python** (for AI/Embeddings) into a single, cohesive workflow.

![Motia RAG Architecture]

## ğŸš€ Features

- **ğŸ“„ PDF Ingestion:** Uploads are streamed, chunked, and saved locally.
- **ğŸ§  Local Embeddings:** Uses `HuggingFace (all-MiniLM-L6-v2)` running locally in Python to generate free vector embeddings.
- **âš¡ Instant Chat:** Uses **Groq (Llama 3)** for near-instant, zero-cost AI responses.
- **ğŸ” Semantic Search:** Stores and retrieves vectors using **Pinecone**.
- **ğŸ”— Event-Driven:** Decoupled architecture using Motia events (`file.uploaded`).

## ğŸ› ï¸ Tech Stack

| Component | Technology | Role |
|-----------|------------|------|
| **Orchestration** | [Motia](https://motia.dev) | Connecting Steps & Events |
| **Backend API** | TypeScript (Node.js) | REST API & Upload Handling |
| **AI Worker** | Python 3.9+ | PDF Parsing & Embedding |
| **LLM** | Groq (Llama 3) | Generative AI Answers |
| **Vector DB** | Pinecone | Storing Knowledge |
| **Embeddings** | HuggingFace | Vectorizing Text (Local) |

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html        # Simple frontend UI
â”œâ”€â”€ steps/
â”‚   â”œâ”€â”€ upload.step.ts    # API: Receives chunks & emits 'file.uploaded'
â”‚   â”œâ”€â”€ chat.step.ts      # API: Search Pinecone & query Groq
â”‚   â”œâ”€â”€ ingest_step.py    # WORKER: Listens for events, embeds PDF
â”‚   â””â”€â”€ frontend.step.ts  # API: Serves the HTML UI
â”œâ”€â”€ uploads/              # Local storage for PDF files
â”œâ”€â”€ .env                  # API Keys
â””â”€â”€ package.json